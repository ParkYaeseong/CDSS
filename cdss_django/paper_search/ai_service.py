import requests
import xml.etree.ElementTree as ET
import google.generativeai as genai
import logging
import json # JSON íŒŒì‹±ì„ ìœ„í•´ ì¶”ê°€
from django.conf import settings

logger = logging.getLogger(__name__)

# --- Gemini API ì´ˆê¸° ì„¤ì • (ì´ì „ê³¼ ë™ì¼) ---
try:
    if hasattr(settings, 'GEMINI_API_KEY') and settings.GEMINI_API_KEY and settings.GEMINI_API_KEY != "YOUR_GEMINI_API_KEY":
        genai.configure(api_key=settings.GEMINI_API_KEY)
        logger.info("âœ… Gemini API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        logger.warning("âš ï¸ ì£¼ì˜: settings.pyì— GEMINI_API_KEYê°€ ìœ íš¨í•˜ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
except Exception as e:
    logger.error(f"ğŸ”´ Gemini API ì„¤ì • ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

# --- í—¬í¼ í•¨ìˆ˜ ì¬ì„¤ê³„ ---

def _search_epmc_fulltext(query: str, limit: int) -> list:
    # ì´ì „ê³¼ ë™ì¼
    logger.info(f"ğŸ‡ªğŸ‡º Europe PMC ê²€ìƒ‰ ì‹œì‘: query='{query}', limit={limit}")
    url = "https://www.ebi.ac.uk/europepmc/webservices/rest/search"
    params = {
        "query": f'({query}) AND (OPEN_ACCESS:"Y")',
        "resultType": "lite",
        "format": "json",
        "pageSize": limit
    }
    try:
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        results = data.get("resultList", {}).get("result", [])
        logger.info(f"âœ… Europe PMC ê²€ìƒ‰ ì™„ë£Œ. {len(results)}ê°œ ê²°ê³¼ ìˆ˜ì‹ .")
        return results
    except requests.exceptions.RequestException as e:
        logger.error(f"ğŸ”´ Europe PMC API ìš”ì²­ ì‹¤íŒ¨: {e}", exc_info=True)
    return []

def _get_epmc_fulltext_xml(pmcid: str) -> str:
    # ì´ì „ê³¼ ë™ì¼
    logger.info(f"ğŸ“„ Europe PMCì—ì„œ XML ì „ë¬¸ ê°€ì ¸ì˜¤ê¸° (PMCID: {pmcid})")
    url = f"https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/fullTextXML"
    try:
        response = requests.get(url, timeout=40)
        response.raise_for_status()
        logger.info(f"âœ… XML ì „ë¬¸ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ (PMCID: {pmcid}).")
        return response.text
    except requests.exceptions.RequestException as e:
        logger.error(f"ğŸ”´ Europe PMC XML ì „ë¬¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (PMCID: {pmcid}): {e}", exc_info=True)
    return ""

def _extract_full_text_from_xml(xml_text: str) -> str:
    """XMLì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    if not xml_text:
        return ""
    try:
        root = ET.fromstring(xml_text)
        # itertext()ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  íƒœê·¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ê³  ê³µë°±ìœ¼ë¡œ ì—°ê²°
        full_text = " ".join(root.itertext())
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì •ë¦¬
        return ' '.join(full_text.split())
    except ET.ParseError as e:
        logger.error(f"ğŸ”´ XML íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return ""

def _generate_summaries_from_text_gemini(full_text: str, keyword: str) -> list:
    """ë…¼ë¬¸ ì „ì²´ í…ìŠ¤íŠ¸ì™€ í‚¤ì›Œë“œë¥¼ ë°›ì•„, AIê°€ ì§ì ‘ ê´€ë ¨ ë¬¸ì¥ì„ ì°¾ê³  ìš”ì•½í•˜ì—¬ JSON ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not full_text:
        return []
    
    logger.info(f"ğŸ¤– Geminiì—ê²Œ í‚¤ì›Œë“œ '{keyword}' ê¸°ë°˜ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ ë° ìš”ì•½ ìš”ì²­...")

    # AIì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê³ , ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì˜ í˜•ì‹ì„ ëª…í™•íˆ ì§€ì •í•˜ëŠ” í”„ë¡¬í”„íŠ¸
    prompt = f"""
    You are an expert medical research assistant. Your task is to analyze the following academic paper text and extract up to 5 key sentences that are most relevant to the keyword "{keyword}".

    For each extracted sentence, provide a concise Korean summary.

    Please return your findings as a single, valid JSON array of objects. Each object in the array should have two keys: "original_sentence" and "korean_summary".

    Do not include any text or explanation outside of the JSON array.

    Keyword: "{keyword}"

    Paper Text:
    ---
    {full_text[:12000]}
    ---
    """
    
    try:
        model = genai.GenerativeModel('models/gemini-1.5-flash-latest')
        response = model.generate_content(prompt)
        
        # AI ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ
        cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        
        logger.info("âœ… Gemini ì‘ë‹µ ìˆ˜ì‹ . JSON íŒŒì‹± ì‹œë„...")
        # JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        summaries = json.loads(cleaned_response)
        
        # ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ì§€, ë‚´ë¶€ ìš”ì†Œê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ ê°„ë‹¨íˆ ê²€ì¦
        if isinstance(summaries, list) and all(isinstance(item, dict) for item in summaries):
            logger.info(f"âœ… JSON íŒŒì‹± ì„±ê³µ! {len(summaries)}ê°œì˜ ìš”ì•½ ìƒì„±.")
            return summaries
        else:
            logger.warning("âš ï¸ Geminiê°€ ë°˜í™˜í•œ JSON í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return []

    except json.JSONDecodeError as e:
        logger.error(f"ğŸ”´ Gemini ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}\në°›ì€ ì‘ë‹µ: {cleaned_response}")
        return []
    except Exception as e:
        logger.error(f"ğŸ”´ Gemini ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return []

# --- ë©”ì¸ ì„œë¹„ìŠ¤ í•¨ìˆ˜ ì¬ì„¤ê³„ ---

def get_epmc_papers_and_summaries(query: str, keyword: str, count: int = 5) -> list:
    """ë…¼ë¬¸ ê²€ìƒ‰, ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ, AI ìš”ì•½ì˜ ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸"""
    logger.info(f"ğŸš€ (v2) EPMC+Gemini ì„œë¹„ìŠ¤ ì‹œì‘: ê²€ìƒ‰ì–´='{query}', í‚¤ì›Œë“œ='{keyword}', ìµœëŒ€ ë…¼ë¬¸ ìˆ˜={count}")
    
    epmc_papers = _search_epmc_fulltext(query, limit=count)
    if not epmc_papers:
        return []

    final_results = []
    for paper_info in epmc_papers:
        pmcid = paper_info.get("pmcid")
        if not pmcid:
            continue

        title = paper_info.get("title")
        logger.info(f"\nğŸ’¡ '{title}' (PMCID: {pmcid}) ë…¼ë¬¸ ì²˜ë¦¬ ì‹œì‘...")
        
        xml_text = _get_epmc_fulltext_xml(pmcid)
        full_text = _extract_full_text_from_xml(xml_text)
        
        # AIì—ê²Œ í…ìŠ¤íŠ¸ì™€ í‚¤ì›Œë“œë¥¼ ì£¼ê³  ìš”ì•½ ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë°›ìŒ
        extracts = _generate_summaries_from_text_gemini(full_text, keyword)
        
        final_results.append({
            "title": title,
            "pmcid": pmcid,
            "epmc_link": f"https://www.ncbi.nlm.nih.gov/pmc/articles/{pmcid}/",
            "keyword_extracts": extracts
        })
            
    logger.info(f"ğŸ (v2) ì„œë¹„ìŠ¤ ì¢…ë£Œ. ì´ {len(final_results)}ê°œ ë…¼ë¬¸ ì²˜ë¦¬ ì™„ë£Œ.")
    return final_results